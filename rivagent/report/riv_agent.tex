\documentclass{article}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
\usepackage{amsmath}
\usepackage{geometry}
\geometry{left=20mm,right=20mm,top=15mm,bottom=15mm}
% \usepackage[margin=25truemm]{geometry}
\title{RivAgent: An agent submitted to the ANAC 2025 ANL league}
\author{Jumpei Kawahara\\Tokyo University of Agriculture and Technology\\kawahara@katfuji.lab.tuat.ac.jp\\Japan}


\begin{document}
\maketitle
\section{Introduction}
　In the ANL 2025 competition, agents are required to coordinate multiple sub-negotiations simultaneously while maximizing the overall utility from the perspective of a central coordinator. 
This structure introduces a unique challenge compared to typical bilateral negotiation settings, as agents must not only evaluate individual offers but also consider the interdependencies among multiple ongoing negotiations.

The agent developed for this competition, named \textbf{RivAgent}, aims to effectively coordinate these sub-negotiations through a combination of expected utility estimation and time-dependent concession strategies. 
One of the key goals of this agent is to adapt its offer generation and acceptance behavior dynamically based on the negotiation progress and the opponent's behavior patterns.

In this report, I detail the architecture and implementation of the RivAgent, focusing on its core strategies: coordination strategy, time-based concession control, bidding logic, and acceptance policy.


\section{The Strategy of RivAgent}
　This section describes the strategy of RivAgent.

\subsection{Valuable Settings}
　This subsection defines the notation and basic settings used in the negotiation strategy, 
including the structure of the negotiation and relevant variables.

\begin{itemize}
	\item $i$: Sub negotiation index ($n$: Total number of sub negotiations)
	\item $t$: step in arbitrary sub negotiation ($T$: Total number of steps)
	\item $a\in A$: Arbitrary outcome that accepting offer
	\item $e$: Outcome that ending negotiation
	\item $o\in O$: Arbitrary outcome ($m$: Total number of outcomes)
\end{itemize}

\subsection{Coordination Strategy}
　This subsection defines coordination strategies used during negotiation.

\subsubsection{OAP: Opponent's Acceptance Probability}
　Opponent's Acceptance Probability (OAP) estimates the probability that the opponent will accept an offer. 
It is used in the calculation of ECU.

\begin{algorithm}[H]
  \caption{Calculate OAP}
  \label{al:calc-oap}
  \begin{algorithmic}[1]{\scriptsize
	\Require Now is $i$-th sub negotiation 
	\Require $\text{Buffer}(\rho) = \{\rho^1,..,\rho^{\beta}\}$
	\State Collect Opponent Offer History ${\overline{X}}=\{{\overline{x}}_0,..,{\overline{x}}_{T_{end}}\}$
	\If {$t > 2m$ and $\frac{t}{T}\geq0.25$}
	\Comment Calculate $\rho$
	\State Calculate $\rho = \frac{\text{CountUnique}({\overline{X}})}{m}$
	\State Append $\rho$ to $\text{Buffer}(\rho)$
	\EndIf
	\If {$\beta=0$}
	\Comment Calculate $OAP$
		\State $OAP = 0.5$
	\Else
		\State Calculate $\rho'=\sum_{j}^{\beta}0.55^{\beta-j}\rho^{j}$
		\State Calculate $OAP = 0.45 + 0.1\rho'$
	\EndIf
	}\end{algorithmic}
\end{algorithm}

\subsubsection{ECU: Expected Center Utility}
　Expected Center Utility (ECU) represents the expected utility of a particular outcome from the perspective of the center, 
taking into account future transitions.
It is used in both the bidding and acceptance strategies.

\begin{algorithm}[H]
  \caption{Build ECU Tree}
  \label{al:build-ecu-tree}
  \begin{algorithmic}[1]{\scriptsize
	\Require Now is $i$-th sub negotiation 
	\Require Already calculated $OAP$
	\For {$j$: $n$ to $i$}
		\ForAll {$o^{j}\in O^{j}$}
		\Comment Calculate ECU using child's ECU
			\If {$j = n$}
				\State $ECU^{n} (o) = \text{CenterUtility}(\{o^1,..,o^{n-1},o\})$
			\Else
				\State $ECU^{j}(o) = p_1ECU^{j+1}(a_{1}) +...+ p_mECU^{j+1}(a_m) + qECU^{j+1}(e)$
				\If {$o$ is END NEGOTIATION}
					\State $ECU^{j}(o)\leftarrow 0.9ECU^{j}(o)$
				\EndIf
			\EndIf
		\EndFor
		\If {${j}>i$}
		\Comment Sort ECUs
			\State $\{ECU^{j}(o_1),..,ECU^{{j}+1}(o_m)\}\leftarrow \text{SortByDescend} (\{ECU^{j}(o_1),..,ECU^{j}(o_m)\})$
			\State Remove $ECU^{j}(o)$ if $ECU^{j}(o) < ECU^{j}(e)$
			\State $p_{rest}=1.0$
			\Comment Calculate Transition Probability
			\For {$k$: $1$ to $m-1$}
				\State $p_k \leftarrow p_{rest}\cdot OAP$
				\State $p_{rest} \leftarrow p_{rest} - p_k$
			\EndFor
			\State $q\leftarrow p_{rest}$
		\EndIf
	\EndFor
	}\end{algorithmic}
\end{algorithm}

\subsection{Time-Based Strategy}
　This subsection presents a time-based strategy that dynamically adjusts offer thresholds depending on the progress of negotiation and the variety of the opponent's past proposals. The level of concession is controlled based on these factors.

\begin{algorithm}[H]
  \caption{Time-Based Strategy}
  \label{al:calc-th-range}
  \begin{algorithmic}[1]\scriptsize{
	\Require Now is $i$-th sub negotiation
	\Require Already calculated $\{ECU^i(a_1),..,ECU^i(a_{m-1}),ECU^i(e)\}$
	\Require $ECU_{max}=ECU^i(a_1)$, $ECU_{min}=ECU^i(e)$
	\For {$t$: $0$ to $T-1$(Not accept and not end negotiation)}
		\If {$t<5$}
		\Comment Calculate $\alpha$
			\State $\alpha=1.7$
		\Else
			\State $\nu=\text{CountUnique}({\overline{x_{t-5}}},..,{\overline{x_{t-1}}})$
			\If {$\nu = 1$}
				\State $\alpha=1.3$
			\Else:
				\State $\alpha=1.7$
			\EndIf
		\EndIf
		\State $TH_{min} = min(ECU_{min}+(ECU_{max}-ECU_{min})(1-\alpha^{\frac{t}{T}}), 0.5ECU^i_{max})$
		\Comment Calculate threshold range
		\State $TH_{max} = max(th_{min}+0.1(ECU^i_{max}-ECU^i_{min}), ECU^i_{max})$
		\State Doing some process
	\EndFor
	}\end{algorithmic}
\end{algorithm}

\subsection{Bidding Strategy}
　This subsection describes the bidding strategy used to select an appropriate offer from a set of candidates that fall within a given threshold range.
The selection is based on ECU values and the diversity of issue values.

\begin{algorithm}[H]
  \caption{Bidding Strategy}
  \label{al:bidding-strategy}
  \begin{algorithmic}[1]\scriptsize{
	\Require Now is $i$-th sub negotiation, and current step is $t$
	\Require Already calculated $\{ECU^i(a_1),..,ECU^i(a_{m-1}),ECU^i(e)\}$
	\Require Already calculated $TH_{min}$, $TH_{max}$
	\Require $L$: Total number of issues
	\State Select offers $\{x_1, .., x_{m'}\}$ (Arbitrary selected offer satisfy $TH_{min} \leq ECU^i(x) \leq TH_{max}$)
	\If {$m'=1$}
		\State Proposal offer ${\hat{x}}=x_1$
	\Else
		\For {$l$: $1$ to $L$}
		\Comment Calculate weight
		\State $w_l=\text{Normalize}(1-\frac{\text{NumbefOfExistValues}(l)}{\text{TotalNumberOfValues}(l)})$
		\EndFor
		\For {$k$: $1$ to $m'$}
		\Comment Calculate preference
			\State $\text{Preference}(x_k)=\sum_l^L w_l Count(x[l])$
		\EndFor
		\State Selected index ${\hat{k}}=\underset{k}{\text{argmax}}\;\text{Preference}(x_k)$
		\Comment Select offer
		\State Proposal offer ${\hat{x}}=x_{\hat{k}}$
	\EndIf
	}\end{algorithmic}
\end{algorithm}

\subsection{Acceptance Strategy}
　This subsection explains the acceptance strategy for incoming offers.
The decision to accept or reject is based on a comparison between the ECU of the opponent's proposal and a predefined threshold.

\begin{algorithm}[H]
  \caption{Acceptance Strategy}
  \label{al:accept-strategy}
  \begin{algorithmic}[1]\scriptsize{
	\Require Now is $i$-th sub negotiation, and current step is $t$
	\Require Already calculated $\{ECU^i(a_1),..,ECU^i(a_{m-1}),ECU^i(e)\}$
	\Require Already calculated $TH_{min}$
	\Require ${\overline{x}}$: Offer proposed by opponent
	\If {$m-1=0$}
		\State End negotiation
	\Else
		\If {$ECU^i({\overline{x}})>TH_{min}$}
			\State Accept offer ${\overline{x}}$
		\Else
			\State Reject offer ${\overline{x}}$
		\EndIf
	\EndIf
	}\end{algorithmic}
\end{algorithm}

\section{Evaluation}
　This section presents the performance of RivAgent.
Tables \ref{tb:dinners-score}, \ref{tb:tq-score}, and \ref{tb:job-score} show a performance comparison between the proposed agent and several baseline agents in the AMR 2025 simulation environment.
RivAgent achieved the highest overall performance, particularly in the Dinners scenario.
Additionally, it recorded the highest mean performance in both the Target Quantity and Job Hunt scenarios.
However, its minimum and first quartile (Q1) scores were lower compared to those of Boulware2025 and Linear2025.

\begin{table}[htbp]
	\centering
	\caption{Dinners Score (1000 tournaments)}
	\label{tb:dinners-score}
	\begin{tabular}{|c|c|r|r|r|r|r|}\hline
		\multicolumn{2}{|c|}{Agent}&\multicolumn{1}{c|}{Min}&\multicolumn{1}{c|}{Q1}&\multicolumn{1}{c|}{Mean}&\multicolumn{1}{c|}{Q3}&\multicolumn{1}{c|}{Max}\\\hline
		RivAgent&final scores&\textbf{1.050}&\textbf{7.018}&\textbf{12.045}&\textbf{16.002}&\textbf{47.600}\\\cline{2-7}
		&weighted average&\textbf{0.053}&\textbf{0.368}&\textbf{0.796}&\textbf{1.340}&\textbf{2.140}\\\hline
		Boulware2025&final scores&0.630&6.420&10.589&13.000&42.000\\\cline{2-7}
		&weighted average&0.035&0.333&0.690&0.917&1.900\\\hline
		Linear2025&final scores&0.840&6.420&10.599&13.000&42.000\\\cline{2-7}
		&weighted average&0.038&0.317&0.700&0.943&1.900\\\hline
		Conceder2025&final scores&0.840&6.210&10.268&12.465&42.000\\\cline{2-7}
		&weighted average&0.042&0.317&0.691&0.953&1.900\\\hline
		Random2025&final scores&0.390&3.477&5.118&6.608&14.000\\\cline{2-7}
		&weighted average&0.018&0.180&0.318&0.444&0.700\\\hline
	\end{tabular}
\end{table}
\begin{table}[H]
	\centering
	\caption{Target Quantity Score (1000 tournaments)}
	\label{tb:tq-score}
	\begin{tabular}{|c|c|r|r|r|r|r|}\hline
		\multicolumn{2}{|c|}{Agent}&\multicolumn{1}{c|}{Min}&\multicolumn{1}{c|}{Q1}&\multicolumn{1}{c|}{Mean}&\multicolumn{1}{c|}{Q3}&\multicolumn{1}{c|}{Max}\\\hline
		RivAgent&final scores&8.150&11.750&\textbf{19.169}&\textbf{26.262}&\textbf{58.000}\\\cline{2-7}
		&weighted average&0.272&0.392&\textbf{1.184}&\textbf{2.122}&\textbf{2.500}\\\hline
		Boulware2025&final scores&\textbf{8.550}&\textbf{12.600}&18.719&23.300&53.200\\\cline{2-7}
		&weighted average&\textbf{0.285}&\textbf{0.420}&1.136&1.828&2.382\\\hline
		Linear2025&final scores&6.500&11.700&17.201&22.000&47.200\\\cline{2-7}
		&weighted average&0.217&0.390&1.036&1.740&2.377\\\hline
		Conceder2025&final scores&7.600&11.050&16.247&20.625&46.400\\\cline{2-7}
		&weighted average&0.253&0.368&0.968&1.603&2.377\\\hline
		Random2025&final scores&4.000&5.450&9.479&12.050&25.600\\\cline{2-7}
		&weighted average&0.133&0.182&0.603&1.000&1.140\\\hline
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{job hunt Score (1000 tournaments)}
	\label{tb:job-score}
	\begin{tabular}{|c|c|r|r|r|r|r|}\hline
		\multicolumn{2}{|c|}{Agent}&\multicolumn{1}{c|}{Min}&\multicolumn{1}{c|}{Q1}&\multicolumn{1}{c|}{Mean}&\multicolumn{1}{c|}{Q3}&\multicolumn{1}{c|}{Max}\\\hline
		RivAgent & final scores & 7.271 & 12.442 & \textbf{81.447} & \textbf{120.859} & \textbf{336.000} \\\cline{2-7}
		         & weighted average & 0.242 & 0.415 & \textbf{6.059} & \textbf{11.600} & \textbf{11.700} \\\hline
		Boulware2025 & final scores & 8.608 & \textbf{12.835} & 78.455 & 120.731 & 336.000 \\\cline{2-7}
		             & weighted average & 0.287 & \textbf{0.428} & 5.868 & 11.629 & 11.700 \\\hline
		Linear2025 & final scores & \textbf{8.738} & 12.183 & 72.858 & 120.578 & 336.000 \\\cline{2-7}
		           & weighted average & \textbf{0.291} & 0.406 & 5.670 & 11.601 & 11.700 \\\hline
		Conceder2025 & final scores & 4.333 & 9.893 & 72.899 & 118.643 & 336.000 \\\cline{2-7}
		             & weighted average & 0.144 & 0.330 & 5.706 & 11.491 & 11.700 \\\hline
		Random2025 & final scores & 3.583 & 5.719 & 52.931 & 87.562 & 256.800 \\\cline{2-7}
		           & weighted average & 0.119 & 0.191 & 4.015 & 8.234 & 9.567 \\\hline
	\end{tabular}
\end{table}

\section{Conclusions}
　Through my participation in ANL 2025, I was able to develop a high-performance agent.
In particular, in the Dinners scenario, the agent achieved the highest scores across all metrics compared to other agents.
In the other scenarios as well, the agent recorded the highest mean, Q3, and maximum scores among all competitors.
This strong performance was largely due to the use of Expected Center Utility (ECU) as a guiding principle for both bidding and acceptance strategies, enabling the agent to make globally optimized decisions instead of relying on local utility evaluations.

However, in the Target Quantity and Job Hunt scenarios, the agent's minimum and Q1 scores were lower than those of Boulware2025 and Linear2025.
I believe this issue stems from insufficient parameter tuning.
For future competitions, I plan to focus more on parameter optimization and resubmit an improved version of the agent.

\end{document}